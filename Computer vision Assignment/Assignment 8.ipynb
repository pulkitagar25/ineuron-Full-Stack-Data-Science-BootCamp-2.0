{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 8"
   ]
  },
  {
   "attachments": {
    "Screenshot-from-2018-10-17-11-14-10.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using our own terms and diagrams, explain INCEPTIONNET ARCHITECTURE.\n",
    "\n",
    "Ans=>\n",
    "\n",
    "InceptionNet architecture is a complex network architecture that utilizes multiple parallel branches with different types of layer operations (such as convolution, pooling, and concatenation) to extract information from the input data. The idea behind the inception block is to allow the network to learn multiple scales of features at once, making the network more robust and capable of capturing more fine-grained details in the data.\n",
    "\n",
    "![Screenshot-from-2018-10-17-11-14-10.webp](attachment:Screenshot-from-2018-10-17-11-14-10.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe the Inception block.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The Inception block is a building block in the InceptionNet architecture. It consists of multiple parallel branches, each performing a different type of layer operation. The outputs of these branches are then concatenated to form a single output feature map. The different branches in the Inception block can include a standard convolutional layer, a pooling layer, and multiple 1x1 convolutional layers. The different branches allow the network to learn different scales of features and make the network more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What is the DIMENSIONALITY REDUCTION LAYER (1 LAYER CONVOLUTIONAL)?\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "A Dimensional Reduction Layer (1 Layer Convolutional) is a convolutional layer with a kernel size of 1x1. It is used to reduce the number of channels in the feature maps and can be used to control the dimensionality of the feature maps in a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. THE IMPACT OF REDUCING DIMENSIONALITY ON NETWORK PERFORMANCE\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Reducing the dimensionality of the feature maps can impact network performance in several ways. On one hand, it can reduce the number of parameters in the network, making the network faster and more computationally efficient. On the other hand, reducing the dimensionality of the feature maps can also result in a loss of information and reduce the performance of the network. In general, the impact of reducing dimensionality will depend on the specific use case and the requirements of the task at hand. It is therefore important to carefully consider the trade-off between computational efficiency and performance when deciding whether to reduce dimensionality in a network.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mention three components. Style GoogLeNet\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Three components of the style of GoogLeNet are the use of inception blocks, multiple parallel paths for processing data, and the use of auxiliary classifiers in the network to increase performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using our own terms and diagrams, explain RESNET ARCHITECTURE.\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The ResNet architecture is a deep convolutional neural network that utilizes skip connections, or shortcuts, between layers to allow information to flow more directly through the network. This helps to mitigate the vanishing gradient problem and allows for the training of much deeper networks than was previously possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What do Skip Connections entail?\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Skip connections in ResNet involve creating a shortcut path between two layers in the network, bypassing one or more layers. This allows information to flow more directly through the network and helps to mitigate the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What is the definition of a residual Block?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "A residual block is a type of building block used in the ResNet architecture. It consists of two or more convolutional layers followed by a summing operation, which combines the output of the convolutional layers with the input to the block. This helps to ensure that the network can learn a residual mapping, or the difference between the desired output and the output of the lower layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. How can transfer learning help with problems?\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Transfer learning can help with problems by leveraging knowledge from pre-trained networks to help train a new network on a different task. This can help to reduce the amount of training data required and speed up the training process, as the pre-trained network has already learned many useful features that can be used to help classify new data. Additionally, transfer learning can help to improve the performance of a new network by leveraging the knowledge gained from the pre-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What is transfer learning, and how does it work?\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Transfer learning is a machine learning technique where a pre-trained model is fine-tuned for a different task, rather than training a model from scratch. This is useful when there is limited training data for the task in question, but there is a large amount of related data available in a pre-trained model. The idea behind transfer learning is to use the features learned from the pre-trained model as a starting point, and then adjust and fine-tune them for the new task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. HOW DO NEURAL NETWORKS LEARN FEATURES? 11. HOW DO NEURAL NETWORKS LEARN FEATURES?\n",
    "\n",
    "Ans=>\n",
    "\n",
    "\n",
    "Neural networks learn features through a process called feature learning or representation learning. During the training process, the weights in the neural network are updated to minimize the loss between the predicted output and the true output. The process of updating the weights involves the learning of meaningful representations of the input data, which can be thought of as the network learning to extract features from the input data. These features can then be used to make predictions about new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. WHY IS FINE-TUNING BETTER THAN START-UP TRAINING?\n",
    "\n",
    "Ans=>\n",
    "\n",
    "\n",
    "Fine-tuning a pre-trained model is better than start-up training because the pre-trained model has already learned a set of features from a large amount of related data. This allows the fine-tuning process to start from a much better place, where the weights are already capturing meaningful representations of the data. Fine-tuning allows the model to quickly adapt to the new task, rather than starting from scratch, which can be much slower and require more data. Additionally, fine-tuning allows the model to make use of any pre-existing knowledge or patterns in the data, which can improve the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
