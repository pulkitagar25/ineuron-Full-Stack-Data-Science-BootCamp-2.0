{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the difference between supervised and unsupervised learning? Give some examples to illustrate your point.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Supervised learning and unsupervised learning are two major categories of machine learning algorithms. In supervised learning, the model is trained using labeled data, where the desired output is provided for each example. The goal of the model is to learn the mapping between the input and output variables so that it can predict the output for new, unseen examples. Examples of supervised learning tasks include regression (predicting a continuous output value), classification (predicting a class label), and sequence labeling (predicting a class label for each element in a sequence).\n",
    "\n",
    "In unsupervised learning, the model is trained on unlabeled data, and the goal is to uncover the underlying structure of the data. The model is not told what the correct output should be, so it must discover it on its own. Examples of unsupervised learning tasks include clustering (grouping similar examples together), anomaly detection (identifying examples that are different from the norm), and dimensionality reduction (representing data in a lower-dimensional space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mention a few unsupervised learning applications.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Some applications of unsupervised learning include:\n",
    "- Market segmentation\n",
    "- Anomaly detection in financial and insurance industries\n",
    "- Image segmentation\n",
    "- Fraud detection\n",
    "- Gene expression analysis\n",
    "- Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What are the three main types of clustering methods? Briefly describe the characteristics of each.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The three main types of clustering methods are:\n",
    "- Centroid-based clustering: This method is based on the idea of finding the center of each cluster, represented by a mean or centroid. The k-means algorithm is an example of a centroid-based clustering method.\n",
    "- Hierarchical clustering: This method builds a hierarchy of clusters, where each cluster is split into smaller clusters until some stopping criterion is met. There are two types of hierarchical clustering: agglomerative (bottom-up) and divisive (top-down).\n",
    "- Density-based clustering: This method clusters together data points that are close to each other in the feature space, and separates data points that are far away from each other. The DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm is an example of a density-based clustering method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explain how the k-means algorithm determines the consistency of clustering.\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The k-means algorithm determines the consistency of clustering by using an iterative optimization process to minimize the sum of squared distances between data points and the centroid of their assigned cluster. The algorithm starts with a randomly initialized set of centroids, and in each iteration, it reassigns data points to the closest centroid and updates the centroids based on the mean of the data points assigned to it. The algorithm repeats these steps until the sum of squared distances stops decreasing, or a maximum number of iterations is reached. The final cluster assignments represent the consistency of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. With a simple illustration, explain the key difference between the k-means and k-medoids algorithms.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The key difference between the k-means and k-medoids algorithms lies in the way they define the centroid of a cluster. In k-means, the centroid of a cluster is defined as the mean of all the data points in the cluster. In k-medoids, the centroid of a cluster is defined as one of the data points in the cluster, which is also referred to as a medoid. The k-medoids algorithm works by selecting k medoids from the data and then assigning each data point to the closest medoid. The medoids are then updated based on the cost function, which measures the sum of distances between each data point and its assigned medoid. The k-medoids algorithm is more robust to outliers compared to the k-means algorithm because the medoids are actual data points and not just a mean."
   ]
  },
  {
   "attachments": {
    "download%20%282%29.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What is a dendrogram, and how does it work? Explain how to do it.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "A dendrogram is a graphical representation of a hierarchical clustering solution. It represents the hierarchy of clusters by showing how individual data points or smaller clusters merge into larger clusters, forming a tree-like structure. Each node in the dendrogram represents a cluster, and the height of the link between two clusters represents the distance between them. The dendrogram is useful for visualizing and interpreting the results of a hierarchical clustering analysis.\n",
    "\n",
    "To create a dendrogram, the first step is to calculate the pairwise distances between all data points. Then, the algorithm starts with each data point as a singleton cluster and merges the two closest clusters until all data points belong to a single cluster. The merging process is represented by a linkage method, which determines how the distance between two clusters is calculated. Common linkage methods include single, complete, average, and ward linkage.\n",
    "![download%20%282%29.png](attachment:download%20%282%29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What exactly is SSE? What role does it play in the k-means algorithm?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "SSE (Sum of Squared Errors) is a metric used to evaluate the performance of the k-means algorithm. It measures the sum of squared distances between each data point and the centroid of its assigned cluster. The goal of the k-means algorithm is to minimize the SSE, so that the cluster assignments are as accurate as possible. The SSE is calculated by taking the sum of the squared distances between each data point and its assigned centroid, and the value of SSE provides a measure of the tightness of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. With a step-by-step algorithm, explain the k-means procedure.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The k-means procedure can be outlined as follows:\n",
    "\n",
    "- Initialize k centroids randomly.\n",
    "\n",
    "- Assign each data point to the closest centroid.\n",
    "\n",
    "- Update the centroids by taking the mean of all data points assigned to it.\n",
    "\n",
    "- Repeat steps 2 and 3 until the centroids stop changing or a maximum number of iterations is reached.\n",
    "\n",
    "- Return the final cluster assignments and centroids.\n",
    "\n",
    "- In the context of hierarchical clustering, the terms \"single link\" and \"complete link\" refer to two linkage methods used to calculate the distance between two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. In the sense of hierarchical clustering, define the terms single link and complete link.\n",
    "\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "Single link refers to the shortest distance between any two data points in different clusters. This linkage method results in chains of clusters, where small clusters are merged into larger clusters based on their proximity.\n",
    "\n",
    "Complete link refers to the longest distance between any two data points in different clusters. This linkage method results in compact clusters, where clusters are merged based on the maximum distance between any two data points in the two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How does the apriori concept aid in the reduction of measurement overhead in a business basket analysis? Give an example to demonstrate your point.\n",
    "\n",
    "\n",
    "Ans=>\n",
    "\n",
    "The apriori concept is used in association rule mining to reduce the measurement overhead in a business basket analysis. The idea behind the apriori concept is that frequent itemsets (i.e., sets of items that frequently occur together) are more likely to be associated with each other than infrequent itemsets. Therefore, the apriori algorithm first identifies frequent itemsets, and then generates association rules based on those frequent itemsets. This reduces the measurement overhead by focusing only on the most frequent itemsets, instead of generating rules for every possible combination of items.\n",
    "For example, consider a business basket analysis of a grocery store. The apriori algorithm could be used to identify the most frequent itemsets among customers, such as bread and butter, bread and jam, and milk and cereal. Based on these frequent itemsets, association rules could be generated, such as \"If a customer buys bread, they are likely to buy butter with a confidence of 70%\". This information can be used by the grocery store to improve its product placement and make targeted promotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
